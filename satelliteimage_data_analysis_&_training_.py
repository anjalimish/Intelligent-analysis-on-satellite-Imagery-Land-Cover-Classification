# -*- coding: utf-8 -*-
"""SatelliteImage_Data_Analysis_&_Training_.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12S23apJ1Q4RZrVM9VVXryq3_TfqONzdl

# **Intelligent Analysis on Satellite Imagery | R&D**
## Land Cover Classification on satellite Imagery

# **Import Packages**
"""

# Commented out IPython magic to ensure Python compatibility.
# import the required libraries  
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline
from fastai.vision import *  # import the vision module
from fastai.metrics import error_rate  # import our evaluation metric
import zipfile # import module to unzip the data
import urllib.request 
import os # import module to access file paths

import shutil
shutil.rmtree('/content/Eurosat-Project/images/HerbaceousVegetation', ignore_errors=True)

!git clone https://github.com/pauldamsa/Eurosat-Project.git

seed_value= 0
import os
os.environ['PYTHONHASHSEED']=str(seed_value)
import random
random.seed(seed_value)
import numpy as np
np.random.seed(seed_value)
import tensorflow as tf
tf.random.set_seed(seed_value)
session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)
sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)
tf.compat.v1.keras.backend.set_session(sess)

from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn import metrics
import os
import pandas as pd
import numpy as np
import seaborn as sns
import math 
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import cv2

"""# **Load Data**"""

class Image:
  """
    This class will be used for mantaining informations about an image
  """
  def __init__(self, category_name):

    
    self.category_name = category_name

    # A list with images of the person
    self.category_images = []
  
  def getCategoryName(self):
    return self.category_name

  def getCategoryImages(self):
    return self.category_images
  
  def addImage(self, image):
    """
      This function is used for adding an image with person to his/her list

      Arguments:
        image: the image we want to add (numpy array)
    """
    self.category_images.append(image)

def testImageClass():
  """
    This function is used for testing the Image class
  """
  img = Image("Vegetation")

  assert img.getCategoryName() == "Vegetation"
  assert img.getCategoryName() != "awd"
  assert len(img.getCategoryImages()) == 0

  img.addImage(3)
  assert len(img.getCategoryImages()) == 1

testImageClass()

class RepositoryImages:
  """
    This class will be used for storing the images
  """
  def __init__(self):

    # A dictionary in this form {category: Image(category, category_images) }
    self.images = {}

  def getAllImages(self):
    """
      This function is used for getting all images 

      Return:
        A list with all images from dict that contains Image objects
    """
    return list(self.images.values())
  
  def find(self, category):
    """
      This function is used for getting the images of a category

      Arguments:
        category: a string which represents the name of the category that we want to find
      
      Return:
        A object Image
    """
    return self.images[category]
  
  def read(self, path_to_dataset):
    """
      This function is used for reading the images from directories

      Arguments:
        path_to_dataset: the path where the images are stored
    """
    directories = os.listdir(path_to_dataset)

    self.images = {}
    print("Total directories: " +str(len(directories)))

    # Iterate thorugh directories of path_to_dataset directory
    for directory in directories:

      # Get the name of each directory
      name_of_images = os.listdir(path_to_dataset + directory)
      print("Current directory: " + directory + " " + str(len(name_of_images)))

      # Iterate through images
      for name_of_image in name_of_images:

        # If the image is already in dictionary
        if directory in self.images.keys():

          # Read the image
          image = cv2.imread(path_to_dataset + directory + "/" + name_of_image)

          # Add new image 
          self.images[directory].addImage(image)

        else:
          # Read the image
          image = Image(directory)
          image.addImage(cv2.imread(path_to_dataset + directory + "/" + name_of_image))
          self.images[directory] = image

def testRepository():
  assert len(repo.getAllImages()) == 10

repository = RepositoryImages()
repository.read("/content/Eurosat-Project/images/")

class Service:
  """
    This class will be used for working with the while database of images
  """
  def __init__(self, repo):
    self.repo = repo
  
  def getAllImages(self):
    """
      This function is used for getting all images

      Return:
        A list with all images
    """
    return self.repo.getAllImages()

  def find(self, name_category):
    """
      This function is used for getting the images of a category

      Arguments:
        name_category: a string which represents the name of the category that we want to find
      
      Return:
        A object Image
    """
    return self.repo.find(name_category)
  
  def make_flat(self,input_list):
    """
      input_list: a list of lists
    """
    flat_list = []
    for sublist in input_list:
        for item in sublist:
            flat_list.append(item)
    return flat_list

  
  def displayImagesOfCategory(self, name_category):
    """
      This function is used for displaying the images of a category

      Arguments:
        name_category: a string which represents the name of a category that we want to see his/her images
    """
    # Define the dimensions of the plot grid 
    list_of_images = self.find(name_category).getCategoryImages()
    dim = math.floor(math.sqrt(len(list_of_images[:100])))
    W_grid = dim
    L_grid = dim

    # fig, axes = plt.subplots(L_grid, W_grid)
    # subplot return the figure object and axes object
    # we can use the axes object to plot specific figures at various locations

    fig, axes = plt.subplots(L_grid, W_grid, figsize = (25,25))

    axes = axes.ravel() 

    index = 0
    for i in np.arange(0, W_grid * L_grid):

        # read and display an image with the selected index    
        axes[i].imshow(cv2.cvtColor(np.uint8(list_of_images[index]), cv2.COLOR_BGR2RGB))
        axes[i].set_title(name_category + "_" + str(i), fontsize = 10)
        index+=1
        axes[i].axis('off')

    plt.subplots_adjust(hspace=0.4)
  
  def displayFrequencyHistogram(self):
    """
      This function is used to show a histogram of image frequency for each category
    """

    # Get all images
    images = self.getAllImages()
    
    frequency = [] # the number of images that corresponds to each category
    categories = [] # the name of each category

    # Iterate through images
    for image in images:
      frequency.append(len(image.getCategoryImages()))
      categories.append(image.getCategoryName())

    fig = go.Figure(data=[go.Bar(x = categories, y = frequency)])  

    fig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',marker_line_width=1.5, opacity=0.6)
    fig.update_layout(title_text = "Image frequency on each category")

    fig.show()
  
  def get_data_frame_of_frequency(self):
    """
      This function is used for getting the distribution of the dataset

      Return:
        A dataframe
    """
    # The rows for dataframe
    rows = []

    # Get images
    images = self.getAllImages()
    
    frequency = [] # the number of images that corresponds to each category
    categories = [] # the name of each category

    # Iterate through images
    for image in images:
      frequency.append(len(image.getCategoryImages()))
      categories.append(image.getCategoryName())
    
    total_images = sum(frequency)

    for i in range(len(categories)):
      category = categories[i]
      number_images_category = frequency[i]

      percent = round((number_images_category * 100) / total_images, 2)

      row = [category, number_images_category, percent, total_images]
      rows.append(row)

    df = pd.DataFrame(data = rows, columns=["Category", "Number of images", "Percent", "Total images"])
    return df

service = Service(repository)

"""# **Display images**

### Display images of AnnualCrop
"""

service.displayImagesOfCategory("BarrenLand")

"""### Display images of Pasture"""

service.displayImagesOfCategory("Pasture")

"""### Display images of Vegetation"""

service.displayImagesOfCategory("Vegetation")

"""### Display images of Urban"""

service.displayImagesOfCategory("Urban")

"""### Display images of Water"""

service.displayImagesOfCategory("Water")

"""# **Distribution analysis**

### Histogram
"""

service.displayFrequencyHistogram()

"""### Tables"""

df = service.get_data_frame_of_frequency()

df.sort_values(by="Percent", ignore_index=True)

df.describe()

df.info()

"""# **ML development**

### Split the data
"""

percent_train = 0.8
percent_val = 0.1
percent_test = 0.1

BarrenLand_imgs = service.find("BarrenLand").getCategoryImages()
Vegetation_imgs = service.find("Vegetation").getCategoryImages()
pasture_imgs = service.find("Pasture").getCategoryImages()
Urban_imgs = service.find("Urban").getCategoryImages()
Water_imgs = service.find("Water").getCategoryImages()
imgs = [BarrenLand_imgs, Vegetation_imgs,  pasture_imgs,Urban_imgs,Water_imgs]

X_train = []
y_train = []

X_val = []
y_val = []

X_test = []
y_test = []

i = 0
for set_imgs in imgs:
  train_index = int(len(set_imgs) * percent_train)
  val_index = int(len(set_imgs) * (percent_train + percent_val))
  test_index = int(len(set_imgs) * (percent_train + percent_val + percent_test))

  X_train += set_imgs[:train_index]
  X_val += set_imgs[train_index + 1: val_index]
  X_test += set_imgs[val_index + 1: test_index]

  y_train += [i for k in range(len(set_imgs[:train_index]))]
  y_val += [i for k in range(len(set_imgs[train_index + 1: val_index]))]
  y_test += [i for k in range(len(set_imgs[val_index + 1: test_index]))]

  i += 1

X_train = np.asarray(X_train, dtype="float32")
y_train = np.asarray(y_train, dtype="float32")

X_val = np.asarray(X_val, dtype="float32")
y_val = np.asarray(y_val, dtype="float32")

X_test = np.asarray(X_test, dtype="float32")
y_test = np.asarray(y_test, dtype="float32")

"""#### Check the distributions of classes"""

fig = go.Figure()

x = ["Train", "Val", "Test"]

fig.add_trace(go.Bar(
    x = x,
    y = [len([0 for i in y_train if i == 0]), len([0 for i in y_val if i == 0]), len([0 for i in y_test if i == 0])],
    name='BarrenLand',
))

fig.add_trace(go.Bar(
    x = x,
    y = [len([0 for i in y_train if i == 1]), len([0 for i in y_val if i == 1]), len([0 for i in y_test if i == 1])],
    name='Urban',
))

fig.add_trace(go.Bar(
    x = x,
    y = [len([0 for i in y_train if i == 2]), len([0 for i in y_val if i == 2]), len([0 for i in y_test if i == 2])],
    name='Vegetation',
))

fig.add_trace(go.Bar(
    x = x,
    y = [len([0 for i in y_train if i == 3]), len([0 for i in y_val if i == 3]), len([0 for i in y_test if i == 3])],
    name='Pasture',
))

fig.add_trace(go.Bar(
    x = x,
    y = [len([0 for i in y_train if i == 4]), len([0 for i in y_val if i == 4]), len([0 for i in y_test if i == 4])],
    name='Water',
))






fig.update_layout(barmode='group', xaxis_tickangle=-45, showlegend=True)
fig.show()

"""### Model

#### Architecture
"""

class BasicBlock(tf.keras.layers.Layer):

    def __init__(self, filter_num, stride=1):
        super(BasicBlock, self).__init__()
        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,
                                            kernel_size=(3, 3),
                                            strides=stride,
                                            padding="same")
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,
                                            kernel_size=(3, 3),
                                            strides=1,
                                            padding="same")
        self.bn2 = tf.keras.layers.BatchNormalization()
        if stride != 1:
            self.downsample = tf.keras.Sequential()
            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,
                                                       kernel_size=(1, 1),
                                                       strides=stride))
            self.downsample.add(tf.keras.layers.BatchNormalization())
        else:
            self.downsample = lambda x: x

    def call(self, inputs, training=None, **kwargs):
        residual = self.downsample(inputs)

        x = self.conv1(inputs)
        x = self.bn1(x, training=training)
        x = tf.nn.relu(x)
        x = self.conv2(x)
        x = self.bn2(x, training=training)

        output = tf.nn.relu(tf.keras.layers.add([residual, x]))

        return output


class BottleNeck(tf.keras.layers.Layer):
    def __init__(self, filter_num, stride=1):
        super(BottleNeck, self).__init__()
        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,
                                            kernel_size=(1, 1),
                                            strides=1,
                                            padding='same')
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,
                                            kernel_size=(3, 3),
                                            strides=stride,
                                            padding='same')
        self.bn2 = tf.keras.layers.BatchNormalization()
        self.conv3 = tf.keras.layers.Conv2D(filters=filter_num * 4,
                                            kernel_size=(1, 1),
                                            strides=1,
                                            padding='same')
        self.bn3 = tf.keras.layers.BatchNormalization()

        self.downsample = tf.keras.Sequential()
        self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num * 4,
                                                   kernel_size=(1, 1),
                                                   strides=stride))
        self.downsample.add(tf.keras.layers.BatchNormalization())

    def call(self, inputs, training=None, **kwargs):
        residual = self.downsample(inputs)

        x = self.conv1(inputs)
        x = self.bn1(x, training=training)
        x = tf.nn.relu(x)
        x = self.conv2(x)
        x = self.bn2(x, training=training)
        x = tf.nn.relu(x)
        x = self.conv3(x)
        x = self.bn3(x, training=training)

        output = tf.nn.relu(tf.keras.layers.add([residual, x]))

        return output


def make_basic_block_layer(filter_num, blocks, stride=1):
    res_block = tf.keras.Sequential()
    res_block.add(BasicBlock(filter_num, stride=stride))

    for _ in range(1, blocks):
        res_block.add(BasicBlock(filter_num, stride=1))

    return res_block


def make_bottleneck_layer(filter_num, blocks, stride=1):
    res_block = tf.keras.Sequential()
    res_block.add(BottleNeck(filter_num, stride=stride))

    for _ in range(1, blocks):
        res_block.add(BottleNeck(filter_num, stride=1))

    return res_block

class ResNet(tf.keras.Model):
    def __init__(self, layer_params):
        super(ResNet, self).__init__()
        self.conv1 = tf.keras.layers.Conv2D(filters=64,
                                            kernel_size=(7, 7),
                                            strides=2,
                                            padding="same")
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),
                                               strides=2,
                                               padding="same")

        self.layer1 = make_bottleneck_layer(filter_num=64,
                                            blocks=layer_params[0])
        self.layer2 = make_bottleneck_layer(filter_num=128,
                                            blocks=layer_params[1],
                                            stride=2)
        self.layer3 = make_bottleneck_layer(filter_num=256,
                                            blocks=layer_params[2],
                                            stride=2)
        self.layer4 = make_bottleneck_layer(filter_num=512,
                                            blocks=layer_params[3],
                                            stride=2)

        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()
        self.fc = tf.keras.layers.Dense(units=10, activation=tf.keras.activations.softmax)

    def call(self, inputs, training=None, mask=None):
        x = self.conv1(inputs)
        x = self.bn1(x, training=training)
        x = tf.nn.relu(x)
        x = self.pool1(x)
        x = self.layer1(x, training=training)
        x = self.layer2(x, training=training)
        x = self.layer3(x, training=training)
        x = self.layer4(x, training=training)
        x = self.avgpool(x)
        output = self.fc(x)

        return output

def resnet_50():
    return ResNet(layer_params=[3, 4, 6, 3])
model = resnet_50()

"""#### Build"""

model.build(input_shape=(None, 64, 64, 3))

"""#### Summary"""

model.summary()

"""### Train"""

tf.keras.backend.clear_session()

# SGD optimizer
sgd_optimizer = tf.optimizers.SGD(learning_rate=0.01,  momentum=0.9)

model.compile(
    optimizer = sgd_optimizer,
    loss = "sparse_categorical_crossentropy",
    metrics = ['accuracy']
)

checkpoint = ModelCheckpoint("/content/model.h5", monitor='val_accuracy', verbose=2, save_best_only=True, mode='max')

history = model.fit(
    x = X_train, 
    y = y_train, 
    validation_data = (X_val, y_val),
    batch_size = 128,
    verbose = 1,
    epochs = 10,
    callbacks = [checkpoint]
  )

"""### Evaluation"""

x = np.arange(10)

fig = go.Figure()

fig.add_trace(go.Scatter(x=x, y= history.history['accuracy'], name="Train"))
fig.add_trace(go.Scatter(x=x, y= history.history['val_accuracy'], name="Validation"))

fig.show()

fig = go.Figure()

fig.add_trace(go.Scatter(x=x, y= history.history['loss'], name="Train"))
fig.add_trace(go.Scatter(x=x, y= history.history['val_loss'], name="Validation"))

fig.show()

model.load_weights("./model.h5")

# Get the accuracy and loss on test set
loss, acc = model.evaluate(X_test,  y_test,batch_size=128, verbose=2)
print('Model, accuracy: {:5.2f}%'.format(100*acc))

y_pred = model.predict(X_test,batch_size=128,verbose=1)

# Get the confusion matrix
conf_matrix = metrics.confusion_matrix(y_test, y_pred.argmax(axis = 1))

# Plot the confusion matrix
figure = plt.figure(figsize=(8, 8))
sns.heatmap(conf_matrix, annot=True,cmap=plt.cm.Blues, fmt="d")
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

# Print the classification Report
class_names = ['BarrenLand', 'Urban','Vegetation',  'Pasture', 'Water' ]
print(metrics.classification_report(y_test, y_pred.argmax(axis=1), target_names=class_names))

"""**Verification and fine tuning of Model**"""

data_path = os.getcwd()
path = datapath4file(data_path+'/Eurosat-Project/images')

tfms = get_transforms(flip_vert=True, max_warp = 0.)

data = ImageDataBunch.from_folder(path, train = ".", 
                                  valid_pct=0.2, 
                                  ds_tfms = tfms, 
                                  size=224, bs = 32).normalize(imagenet_stats)

data.show_batch(rows=3, figsize=(12,8))

learn = cnn_learner(data, models.resnet50, metrics=error_rate)

print(learn.summary())

learn.lr_find()
learn.recorder.plot(suggestion=True)

learn.show_results(rows=3, figsize=(10,10))

"""set the learning rate"""

lr = 3.63E-03
learn.fit_one_cycle(6, slice(lr))

learn.unfreeze()
learn.fit_one_cycle(3, slice(1e-6, lr/10))

learn.freeze()
learn.lr_find()
learn.recorder.plot()

"""Improved Prediction Accuracy"""

learn.fit_one_cycle(1, slice(1e-5/2))

interp = ClassificationInterpretation.from_learner(learn)
losses,idxs = interp.top_losses()
len(data.valid_ds)==len(losses)==len(idxs)

"""Confusion Matrix After Improving the accuracy of the Model"""

interp.plot_confusion_matrix(figsize=(6,6), dpi=100)

interp.most_confused(min_val=5)

interp.most_confused(min_val=5)

"""**Results of Predictions**"""

learn.show_results(rows=3, figsize=(10,10))

learn.show_results(rows=3, figsize=(10,10))

learn.export()
learn = load_learner(path)

learn.data.classes